# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import os
import glob
import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from datetime import datetime
from dateutil import parser
import pytesseract
import unicodedata

# Biblioth√®ques Hugging Face
from datasets import Dataset, Features, Sequence, ClassLabel, Value
from datasets import Image as HFImage
from transformers import (
    LayoutLMv3ForTokenClassification,
    LayoutLMv3Processor,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
from transformers.data.data_collator import default_data_collator
import evaluate
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# ==============================================================================
# 1. CONFIGURATION & CHEMINS
# ==============================================================================
# Chemin racine de ton dataset YOLO (celui avec images, labels, classes.txt)
DATASET_ROOT_PATH = "project-1-at-2025-12-23-08-44-924b6b4a" 
IMAGES_DIR = os.path.join(DATASET_ROOT_PATH, "images")
LABELS_DIR = os.path.join(DATASET_ROOT_PATH, "labels")
CLASSES_FILE = os.path.join(DATASET_ROOT_PATH, "classes.txt")

OUTPUT_DIR = "./model/checkpoint"
FINAL_MODEL_DIR = "./model/final"

# Configuration Tesseract (Si sous Windows, d√©commentez la ligne ci-dessous)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Chargement dynamique des classes
# def get_labels_from_file(classes_path):
#     if not os.path.exists(classes_path):
#         print("‚ö†Ô∏è classes.txt non trouv√©, utilisation de classes par d√©faut.")
#         return ["O", "DATE_DELIVRANCE", "DATE_EXPIRATION"] # Fallback
#     with open(classes_path, 'r', encoding='utf-8') as f:
#         labels = [line.strip() for line in f.readlines() if line.strip()]
#     return labels

# LABEL_LIST = get_labels_from_file(CLASSES_FILE)
# ID2LABEL = {i: label for i, label in enumerate(LABEL_LIST)}
# LABEL2ID = {label: i for i, label in enumerate(LABEL_LIST)}

# print(f"‚úÖ Classes charg√©es ({len(LABEL_LIST)}) : {LABEL_LIST}")



# Dossier racine contenant tous les sous-dossiers (OldcniVersoWNY, cniKros, etc.)
# Adapte ce chemin vers ton dossier "General"
ROOT_DIR = "/kaggle/input/verif-et-val-docs-trafic-networking/General" 

# Liste des sous-dossiers √† inclure
SUB_DIRS = [
    "OldcniVersoWNY", "cniKros", "cniNGHOGUE", "cniNOUNDJEU", 
    "cniWatcho", "newcniWNY", "passeports", "permis"
]

def normalize_label(label):
    """
    Nettoie un label : minuscule, sans accent, sans espaces superflus.
    Ex: 'Date de D√©livrance' -> 'date de delivrance'
    Ex: 'QR Code' -> 'qr code'
    """
    # 1. Minuscule et strip
    label = label.lower().strip()
    # 2. Retirer les accents (Unicode Normalization)
    label = ''.join(c for c in unicodedata.normalize('NFD', label) if unicodedata.category(c) != 'Mn')
    return label

def build_global_label_map(root_dir, sub_dirs):
    """
    Parcourt tous les fichiers classes.txt pour cr√©er une liste unique de labels.
    Retourne :
      - global_labels : liste tri√©e de tous les noms de classes uniques
      - global_label2id : dict {nom: id_global}
    """
    unique_labels = set()
    print(f"üîç Construction et nettoyage du dictionnaire global...")
    
    print(f"üîç Analyse des classes dans {len(sub_dirs)} dossiers...")
    
    for folder in sub_dirs:
        class_file = os.path.join(root_dir, folder, "classes.txt")
        if os.path.exists(class_file):
            with open(class_file, 'r', encoding='utf-8') as f:
                # On nettoie et on ajoute au set pour d√©doublonner
                for line in f:
                    clean_lbl = normalize_label(line)
                    if clean_lbl: # Si pas vide
                        unique_labels.add(clean_lbl)
                # labels = [line.strip() for line in f.readlines() if line.strip()]
                # unique_labels.update(labels)
        else:
            print(f"‚ö†Ô∏è Attention : Pas de classes.txt dans {folder}")
    
    
    # On trie pour que l'ordre soit d√©terministe
    # global_labels = sorted(list(unique_labels))
    # return global_labels, {l: i for i, l in enumerate(global_labels)}
        
    # On trie pour que l'ordre soit d√©terministe
    global_labels = sorted(list(unique_labels))
    global_label2id = {label: idx for idx, label in enumerate(global_labels)}
    global_id2label = {idx: label for idx, label in enumerate(global_labels)}
    
    return global_labels, global_label2id, global_id2label

# Construction de la map globale
LABEL_LIST, LABEL2ID, ID2LABEL = build_global_label_map(ROOT_DIR, SUB_DIRS)

print(f"‚úÖ Dictionnaire global construit ({len(LABEL_LIST)} classes) :")
print(LABEL_LIST)


# ==============================================================================
# 2. CHARGEMENT ET OCR (YOLO + TESSERACT -> LayoutLM)
# ==============================================================================
def yolo_to_layoutlm_bbox(x_c_n, y_c_n, w_n, h_n):
    """Convertit YOLO (x_c, y_c, w, h) normalis√© -> LayoutLM (x1, y1, x2, y2) 0-1000"""
    x1 = (x_c_n - w_n / 2) * 1000
    y1 = (y_c_n - h_n / 2) * 1000
    x2 = (x_c_n + w_n / 2) * 1000
    y2 = (y_c_n + h_n / 2) * 1000
    return [int(max(0, min(1000, val))) for val in [x1, y1, x2, y2]]

# def load_data_from_yolo_with_ocr(images_dir, labels_dir):
#     dataset_data = []
#     image_paths = glob.glob(os.path.join(images_dir, "*.*"))
#     valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif'}
#     image_paths = [p for p in image_paths if os.path.splitext(p)[1].lower() in valid_exts]
    
#     print(f"üîÑ Lancement de l'OCR et conversion sur {len(image_paths)} images...")
    
#     for idx, img_path in enumerate(image_paths):
#         filename = os.path.basename(img_path)
#         name_no_ext = os.path.splitext(filename)[0]
#         label_path = os.path.join(labels_dir, name_no_ext + ".txt")
        
#         if not os.path.exists(label_path):
#             continue

#         try:
#             image = Image.open(img_path).convert("RGB")
#             width, height = image.size
#         except Exception as e:
#             print(f"‚ö†Ô∏è Erreur lecture image {filename}: {e}")
#             continue

#         tokens = []
#         bboxes = []
#         ner_tags = []

#         with open(label_path, 'r') as f:
#             for line in f:
#                 parts = line.strip().split()
#                 if len(parts) < 5: continue
                
#                 class_id = int(parts[0])
#                 x_c, y_c, w, h = map(float, parts[1:5])
                
#                 # 1. Conversion coordonn√©es LayoutLM
#                 bbox_1000 = yolo_to_layoutlm_bbox(x_c, y_c, w, h)
                
#                 # 2. Conversion pixels pour Crop OCR (avec padding l√©ger)
#                 pad = 5 # Marge de s√©curit√© pour l'OCR
#                 left = max(0, (x_c - w/2) * width - pad)
#                 top = max(0, (y_c - h/2) * height - pad)
#                 right = min(width, (x_c + w/2) * width + pad)
#                 bottom = min(height, (y_c + h/2) * height + pad)
                
#                 crop = image.crop((left, top, right, bottom))
                
#                 # OCR : psm 7 = Treat the image as a single text line.
#                 text = pytesseract.image_to_string(crop, config='--psm 7').strip()
#                 if not text: text = "-" # Placeholder
                
#                 tokens.append(text)
#                 bboxes.append(bbox_1000)
#                 ner_tags.append(class_id)
        
#         if len(tokens) > 0:
#             dataset_data.append({
#                 "id": name_no_ext,
#                 "image": image,
#                 "tokens": tokens,
#                 "bboxes": bboxes,
#                 "ner_tags": ner_tags
#             })

#     return dataset_data

# # Chargement ou donn√©es factices pour le test
# if os.path.exists(IMAGES_DIR):
#     raw_data = load_data_from_yolo_with_ocr(IMAGES_DIR, LABELS_DIR)
# else:
#     print("‚ö†Ô∏è DOSSIER NON TROUV√â. G√©n√©ration de donn√©es factices.")
#     raw_data = [{"id": "mock", "image": Image.new('RGB', (224, 224), 'white'), "tokens": ["TEST"], "bboxes": [[0,0,100,100]], "ner_tags": [0]}]


def load_all_datasets(root_dir, sub_dirs, global_label2id):
    all_data = []
    
    print("üöÄ D√©marrage du chargement et OCR multi-dossiers...")

    for folder in sub_dirs:
        folder_path = os.path.join(root_dir, folder)
        images_dir = os.path.join(folder_path, "images")
        labels_dir = os.path.join(folder_path, "labels")
        class_file = os.path.join(folder_path, "classes.txt")

        # 1. Charger les classes LOCALES de ce dossier sp√©cifique
        if not os.path.exists(class_file):
            print(f"‚è≠Ô∏è  Ignor√© (pas de classes.txt) : {folder}")
            continue
            
        with open(class_file, 'r', encoding='utf-8') as f:
            # local_labels = [line.strip() for line in f.readlines() if line.strip()]
            local_labels = [normalize_label(line) for line in f.readlines()]
            # On stocke le mapping ID_LOCAL -> NOM_NETTOY√â
            local_id_to_name = {}
            for idx, line in enumerate(f.readlines()):
                clean_name = normalize_label(line)
                if clean_name:
                    local_id_to_name[idx] = clean_name
                    
        # Mapping : ID Local (0,1,2) -> Nom ("DATE") -> ID Global (15)
        local_id_to_name = {i: name for i, name in enumerate(local_labels) if name}

        # 2. Lister les images
        image_paths = glob.glob(os.path.join(images_dir, "*.*"))
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif'}
        image_paths = [p for p in image_paths if os.path.splitext(p)[1].lower() in valid_exts]

        # Compteur pour debug
        loaded_count = 0
        
        print(f"   üìÇ Traitement de '{folder}' : {len(image_paths)} images")

        for img_path in image_paths:
            filename = os.path.basename(img_path)
            name_no_ext = os.path.splitext(filename)[0]
            label_path = os.path.join(labels_dir, name_no_ext + ".txt")
            
            if not os.path.exists(label_path):
                continue

            try:
                image = Image.open(img_path).convert("RGB")
                width, height = image.size
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur image {filename}: {e}")
                continue

            tokens = []
            bboxes = []
            ner_tags = []

            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) < 5: continue
                    
                    local_class_id = int(parts[0])
                    
                    # --- ETAPE CRUCIALE : REMAPPING ---
                    # Si l'ID local n'existe pas dans le classes.txt local, on ignore
                    if local_class_id not in local_id_to_name:
                        continue
                        
                    class_name_clean = local_id_to_name[local_class_id]
                    
                    # On retrouve l'ID Global correspondant √† ce nom
                    if class_name_clean not in global_label2id:
                        # Cas rare : une classe trouv√©e dans le txt mais pas vue au scan initial ?
                        continue
                    global_class_id = global_label2id[class_name_clean]
                    # ----------------------------------

                    x_c, y_c, w, h = map(float, parts[1:5])
                    
                    # Conversion BBox
                    bbox_1000 = yolo_to_layoutlm_bbox(x_c, y_c, w, h)
                    
                    # OCR (Crop & Read)
                    pad = 5
                    left = max(0, (x_c - w/2) * width - pad)
                    top = max(0, (y_c - h/2) * height - pad)
                    right = min(width, (x_c + w/2) * width + pad)
                    bottom = min(height, (y_c + h/2) * height + pad)
                    
                    crop = image.crop((left, top, right, bottom))
                    text = pytesseract.image_to_string(crop, config='--psm 7').strip()
                    if not text: text = "-"
                    
                    tokens.append(text)
                    bboxes.append(bbox_1000)
                    ner_tags.append(global_class_id) # On ajoute l'ID GLOBAL
            
            if len(tokens) > 0:
                all_data.append({
                    "id": f"{folder}_{name_no_ext}", # ID unique combinant dossier et nom
                    "image": image,
                    "tokens": tokens,
                    "bboxes": bboxes,
                    "ner_tags": ner_tags
                })
                loaded_count += 1
                
        print(f"   üìÇ {folder} : {loaded_count} images charg√©es")
    
    return all_data

# Chargement des donn√©es
if os.path.exists(ROOT_DIR):
    raw_data = load_all_datasets(ROOT_DIR, SUB_DIRS, LABEL2ID)
else:
    print("‚ö†Ô∏è DOSSIER RACINE NON TROUV√â. Assurez-vous que 'General' est au bon endroit.")
    # Fallback factice
    raw_data = []

print(f"‚úÖ Total images charg√©es et converties : {len(raw_data)}")



# Cr√©ation du Dataset HF
# features = Features({
#     "id": Value("string"),
#     "image": "image",
#     "tokens": Sequence(Value("string")),
#     "bboxes": Sequence(Sequence(Value("int64"), length=4)),
#     "ner_tags": Sequence(ClassLabel(num_classes=len(LABEL_LIST), names=LABEL_LIST))
# })
# full_dataset = Dataset.from_list(raw_data, features=features)
# dataset_split = full_dataset.train_test_split(test_size=0.2)
# train_dataset = dataset_split["train"]
# test_dataset = dataset_split["test"]



# Cr√©ation du Dataset HF
# Important : on utilise bien la LABEL_LIST globale ici
features = Features({
    "id": Value("string"),
    "image": HFImage(),
    "tokens": Sequence(Value("string")),
    "bboxes": Sequence(Sequence(Value("int64"), length=4)),
    "ner_tags": Sequence(ClassLabel(num_classes=len(LABEL_LIST), names=LABEL_LIST))
})

full_dataset = Dataset.from_list(raw_data, features=features)
dataset_split = full_dataset.train_test_split(test_size=0.2)
train_dataset = dataset_split["train"]
test_dataset = dataset_split["test"]


# ==============================================================================
# 3. PRE-TRAITEMENT (PROCESSOR)
# ==============================================================================
processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)

def prepare_examples(examples):
    images = examples["image"]
    words = examples["tokens"]
    boxes = examples["bboxes"]
    word_labels = examples["ner_tags"]

    encoding = processor(
        images,
        words,
        boxes=boxes,
        word_labels=word_labels,
        truncation=True,
        padding="max_length",
        max_length=512,
        return_tensors="pt"
    )
    return encoding

remove_columns = train_dataset.column_names
train_dataset = train_dataset.map(prepare_examples, batched=True, remove_columns=remove_columns)
test_dataset = test_dataset.map(prepare_examples, batched=True, remove_columns=remove_columns)

train_dataset.set_format(type="torch")
test_dataset.set_format(type="torch")

# ==============================================================================
# 4. DEFINITION DU MODELE ET FREEZING (GEL DES POIDS)
# ==============================================================================
model = LayoutLMv3ForTokenClassification.from_pretrained(
    "microsoft/layoutlmv3-base",
    num_labels=len(LABEL_LIST),
    id2label=ID2LABEL,
    label2id=LABEL2ID
)

# --- FREEZING (GEL DES POIDS) ---
# On g√®le le corps du mod√®le (layoutlmv3) pour ne laisser que la t√™te de classification s'entra√Æner
# Utile quand on a peu de donn√©es pour √©viter l'overfitting
for name, param in model.layoutlmv3.named_parameters():
    param.requires_grad = False

print("‚ùÑÔ∏è Poids du mod√®le de base gel√©s. Seule la 'head' sera entra√Æn√©e.")

# ==============================================================================
# 5. METRIQUES ET EVALUATION
# ==============================================================================
metric = evaluate.load("seqeval")

def compute_metrics(p):
    predictions, labels = p
    predictions = np.argmax(predictions, axis=2)

    true_predictions = [
        [LABEL_LIST[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    true_labels = [
        [LABEL_LIST[l] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]

    results = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        # "precision": results["overall_precision"],
        # "recall": results["overall_recall"],
        # "f1": results["overall_f1"],
        # "accuracy": results["overall_accuracy"],
        "accuracy": accuracy_score(true_labels, true_predictions),
        "f1": f1_score(true_labels, true_predictions, average="weighted"),
        "precision": precision_score(true_labels, true_predictions, average="weighted", zero_division=0),
        "recall": recall_score(true_labels, true_predictions, average="weighted", zero_division=0),
    }

# ==============================================================================
# 6. CONFIGURATION DE L'ENTRAINEMENT
# ==============================================================================
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    max_steps=500, # Ajuster selon la taille du dataset
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    learning_rate=5e-5,
    eval_strategy="steps",
    eval_steps=50,
    save_strategy="steps",
    save_steps=50,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    report_to=["tensorboard"],
    logging_steps=10
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=processor,
    data_collator=default_data_collator,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]
)

# ==============================================================================
# 7. EVALUATION AVANT FINE-TUNING
# ==============================================================================
print("üìä Evaluation des performances AVANT Fine-Tuning...")
pre_train_metrics = trainer.evaluate()
print(f"Pre-train metrics: {pre_train_metrics}")

# ==============================================================================
# 8. LANCEMENT DU FINE-TUNING ET SAUVEGARDE
# ==============================================================================
print("üöÄ D√©marrage du Fine-Tuning...")
trainer.train()

# Sauvegarde finale
trainer.save_model(FINAL_MODEL_DIR)
processor.save_pretrained(FINAL_MODEL_DIR)
print(f"‚úÖ Mod√®le sauvegard√© dans {FINAL_MODEL_DIR}")

# ==============================================================================
# 9. RAPPORT GRAPHIQUE ET COMPARAISON
# ==============================================================================
print("üìä Evaluation des performances APRES Fine-Tuning...")
post_train_metrics = trainer.evaluate()

history = trainer.state.log_history

# Extraction des donn√©es
eval_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]
eval_f1 = [x['eval_f1'] for x in history if 'eval_f1' in x]
steps = [x['step'] for x in history if 'eval_loss' in x]

# Cr√©ation du dossier final s'il n'existe pas
os.makedirs(FINAL_MODEL_DIR, exist_ok=True)

# G√©n√©ration des graphes
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(steps, eval_loss, label='Validation Loss', color='red')
plt.title('Evolution de la Loss')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(steps, eval_f1, label='Validation F1', color='green')
plt.title('Evolution du F1 Score')
plt.xlabel('Steps')
plt.ylabel('F1 Score')
plt.legend()

plt.tight_layout()
plt.savefig(os.path.join(FINAL_MODEL_DIR, "training_report.png"))
print(f"üìà Rapport graphique sauvegard√© dans {FINAL_MODEL_DIR}")

# Tableau comparatif
comparison_df = pd.DataFrame({
    "Metrique": ["Loss", "Accuracy", "Recall", "F1"],
    "Avant Tuning": [pre_train_metrics.get("eval_loss", "N/A"), pre_train_metrics["eval_accuracy"], pre_train_metrics["eval_recall"], pre_train_metrics["eval_f1"]],
    "Apr√®s Tuning": [post_train_metrics["eval_loss"], post_train_metrics["eval_accuracy"], post_train_metrics["eval_recall"], post_train_metrics["eval_f1"]]
})
print("\n=== COMPARATIF AVANT / APRES ===")
print(comparison_df)

# ==============================================================================
# 10. LOGIQUE METIER : CLASSIFICATION ET VALIDITE
# ==============================================================================
def check_document_validity(extracted_dates, doc_type="CNI"):
    """
    V√©rifie la validit√© d'un document bas√© sur les dates extraites.
    extracted_dates: dictionnaire ex: {'DATE_EXPIRATION': '12/05/2026', 'DATE_DELIVRANCE': '...'}
    """
    today = datetime.now()
    status = "VALIDE"
    message = "Document valide."
    
    date_delivrance = None
    date_expiration = None
    
    # Tentative de parsing des dates (format JJ/MM/AAAA)
    try:
        if "DATE_DELIVRANCE" in extracted_dates and extracted_dates["DATE_DELIVRANCE"] != "-":
            date_delivrance = parser.parse(extracted_dates["DATE_DELIVRANCE"], dayfirst=True)
        if "DATE_EXPIRATION" in extracted_dates and extracted_dates["DATE_EXPIRATION"] != "-":
            date_expiration = parser.parse(extracted_dates["DATE_EXPIRATION"], dayfirst=True)
    except Exception as e:
        return "ERREUR", f"Format de date illisible: {str(e)}"

    # R√®gle 1 : Expiration explicite
    if date_expiration:
        if date_expiration < today:
            status = "EXPIRE"
            message = f"Document expir√© le {date_expiration.strftime('%d/%m/%Y')}."
        else:
            message = f"Valide jusqu'au {date_expiration.strftime('%d/%m/%Y')}."
            
    # R√®gle 2 : Calcul th√©orique (CNI Cameroun = 10 ans)
    elif date_delivrance:
        validity_years = 10 
        expiry_theoretical = date_delivrance.replace(year=date_delivrance.year + validity_years)
        
        if expiry_theoretical < today:
            status = "EXPIRE"
            message = f"Document expir√© (D√©livr√© le {date_delivrance.strftime('%d/%m/%Y')} + {validity_years} ans)."
        else:
            message = f"Valide (D√©livr√© le {date_delivrance.strftime('%d/%m/%Y')})."
    else:
        status = "INCERTAIN"
        message = "Aucune date exploitable trouv√©e."

    return status, message

# --- Simulation d'utilisation m√©tier ---
print("\n=== TEST DE VALIDIT√â (Simulation sur donn√©es fictives) ===")
# Ici, dans un cas r√©el, vous prendriez les outputs du mod√®le pour reconstruire ces cha√Ænes
simulated_extraction_ok = {"DATE_EXPIRATION": "20/05/2030"} 
simulated_extraction_ko = {"DATE_EXPIRATION": "01/01/2020"}

statut_ok, msg_ok = check_document_validity(simulated_extraction_ok)
print(f"[Cas 1] : {statut_ok} | {msg_ok}")

statut_ko, msg_ko = check_document_validity(simulated_extraction_ko)
print(f"[Cas 2] : {statut_ko} | {msg_ko}")








import os
import shutil
import yaml
import torch
import cv2
import glob
import random
import pandas as pd
import matplotlib.pyplot as plt
import pytesseract
from datetime import datetime
from dateutil import parser
from ultralytics import YOLO

# ==============================================================================
# 1. CONFIGURATION & CHEMINS
# ==============================================================================
WORKING_DIR = "/kaggle/working"
PROJECT_NAME = "document_analysis"
RUN_NAME = "checkpoint_run"
MODEL_DIR = os.path.join(WORKING_DIR, PROJECT_NAME, RUN_NAME)
FINAL_MODEL_PATH = os.path.join(MODEL_DIR, "weights", "best.pt")

# ‚ö†Ô∏è IMPORTANT : Mettez ici le chemin RACINE de votre dataset sur Kaggle
# Si votre dataset s'appelle "mon-dataset" et contient le dossier "General", ce sera probablement :
# "/kaggle/input/mon-dataset/General" ou juste "/kaggle/input/mon-dataset"
INPUT_DATASET_ROOT = "/kaggle/input/verif-et-val-docs-trafic-networking/General" 

# Dossier temporaire o√π on va r√©organiser les donn√©es pour YOLO
TEMP_DATASET_DIR = os.path.join(WORKING_DIR, "dataset_ready")

# ==============================================================================
# 2. PR√âPARATION AUTOMATIQUE DU DATASET (SPLIT TRAIN/VAL)
# ==============================================================================

# def prepare_dataset_structure(source_root, dest_root, split_ratio=0.8):
#     """
#     Parcourt l'arborescence complexe, rassemble images/labels,
#     cr√©e le split train/val et g√©n√®re le YAML.
#     """
#     print(f"üîÑ Pr√©paration du dataset depuis : {source_root}")
    
#     # Cr√©ation des dossiers de destination
#     dirs = {
#         'train_img': os.path.join(dest_root, 'images', 'train'),
#         'val_img': os.path.join(dest_root, 'images', 'val'),
#         'train_lbl': os.path.join(dest_root, 'labels', 'train'),
#         'val_lbl': os.path.join(dest_root, 'labels', 'val')
#     }
#     for d in dirs.values():
#         os.makedirs(d, exist_ok=True)

#     # Collecte de toutes les paires (image, label)
#     all_pairs = []
#     class_names = []
    
#     # On cherche r√©cursivement les dossiers 'images'
#     # On suppose que pour chaque dossier 'images', il y a un dossier 'labels' fr√®re
#     for root, d_names, f_names in os.walk(source_root):
#         if os.path.basename(root) == 'images':
#             label_dir = root.replace('images', 'labels')
            
#             # Essayer de trouver classes.txt dans le dossier parent pour r√©cup√©rer les noms
#             parent_dir = os.path.dirname(root)
#             classes_file = os.path.join(parent_dir, 'classes.txt')
#             if os.path.exists(classes_file) and not class_names:
#                 with open(classes_file, 'r') as f:
#                     class_names = [line.strip() for line in f.readlines() if line.strip()]
            
#             # Lister les images
#             for img_file in f_names:
#                 if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
#                     src_img_path = os.path.join(root, img_file)
                    
#                     # Trouver le label correspondant (.txt)
#                     label_name = os.path.splitext(img_file)[0] + ".txt"
#                     src_lbl_path = os.path.join(label_dir, label_name)
                    
#                     if os.path.exists(src_lbl_path):
#                         all_pairs.append((src_img_path, src_lbl_path))

#     print(f"üì¶ Total images trouv√©es avec labels : {len(all_pairs)}")
    
#     if len(all_pairs) == 0:
#         raise ValueError("‚ùå Aucune image/label trouv√©s ! V√©rifiez le chemin INPUT_DATASET_ROOT.")

#     # M√©langer et splitter
#     random.seed(42)
#     random.shuffle(all_pairs)
    
#     split_idx = int(len(all_pairs) * split_ratio)
#     train_pairs = all_pairs[:split_idx]
#     val_pairs = all_pairs[split_idx:]
    
#     print(f"üîπ Train set : {len(train_pairs)} images")
#     print(f"üîπ Val set   : {len(val_pairs)} images")

#     # Fonction de copie
#     def copy_files(pairs, img_dest, lbl_dest):
#         for img_p, lbl_p in pairs:
#             shutil.copy(img_p, img_dest)
#             shutil.copy(lbl_p, lbl_dest)

#     print("‚è≥ Copie des fichiers en cours (cela peut prendre quelques secondes)...")
#     copy_files(train_pairs, dirs['train_img'], dirs['train_lbl'])
#     copy_files(val_pairs, dirs['val_img'], dirs['val_lbl'])
    
#     # Cr√©ation du YAML
#     # Si classes.txt n'a pas √©t√© trouv√©, on met des noms par d√©faut
#     if not class_names:
#         print("‚ö†Ô∏è Attention : 'classes.txt' non trouv√©. Utilisation de noms g√©n√©riques.")
#         # On lit un fichier label au hasard pour deviner le nombre de classes (max id)
#         max_id = 0
#         with open(all_pairs[0][1], 'r') as f:
#             for line in f:
#                 parts = line.split()
#                 if parts:
#                     max_id = max(max_id, int(parts[0]))
#         class_names = [f"class_{i}" for i in range(max_id + 1)]

#     yaml_content = {
#         'path': dest_root,
#         'train': 'images/train',
#         'val': 'images/val',
#         'names': {i: name for i, name in enumerate(class_names)}
#     }
    
#     yaml_path = os.path.join(WORKING_DIR, 'data.yaml')
#     with open(yaml_path, 'w') as f:
#         yaml.dump(yaml_content, f)
        
#     return yaml_path, class_names

# # Lancement de la pr√©paration
# try:
#     YAML_PATH, CLASS_NAMES = prepare_dataset_structure(INPUT_DATASET_ROOT, TEMP_DATASET_DIR)
#     print(f"‚úÖ Dataset pr√™t ! YAML cr√©√© ici : {YAML_PATH}")
#     print(f"üìã Classes : {CLASS_NAMES}")
# except Exception as e:
#     print(f"‚ùå Erreur lors de la pr√©paration du dataset : {e}")
#     # Arr√™t du script si le dataset n'est pas bon
#     exit()


def merge_and_remap_datasets(source_root, dest_root, split_ratio=0.8):
    print(f"üîÑ D√©but de la fusion et du remapping depuis : {source_root}")
    
    # Cr√©ation des dossiers de destination
    dirs = {
        'train_img': os.path.join(dest_root, 'images', 'train'),
        'val_img': os.path.join(dest_root, 'images', 'val'),
        'train_lbl': os.path.join(dest_root, 'labels', 'train'),
        'val_lbl': os.path.join(dest_root, 'labels', 'val')
    }
    for d in dirs.values():
        if os.path.exists(d): shutil.rmtree(d) # Nettoyage si existe d√©j√†
        os.makedirs(d, exist_ok=True)

    # 1. Identifier tous les sous-dossiers contenant un fichier classes.txt
    # On suppose la structure : General/SousDossier/classes.txt
    sub_datasets = []
    
    # On cherche les fichiers classes.txt
    for root, dirs_list, files in os.walk(source_root):
        if 'classes.txt' in files:
            sub_datasets.append(root)

    print(f"üìÇ Sous-datasets d√©tect√©s : {len(sub_datasets)}")
    
    # 2. Construire la liste GLOBALE des classes
    global_classes = [] # Liste unique de toutes les classes
    
    # Dictionnaire pour stocker le mapping de chaque dossier
    # format: { 'chemin/vers/dossier': { id_local: 'NomClasse' } }
    folder_mappings = {}

    for folder in sub_datasets:
        classes_file = os.path.join(folder, 'classes.txt')
        with open(classes_file, 'r') as f:
            # On nettoie les espaces et sauts de ligne
            local_classes = [line.strip() for line in f.readlines() if line.strip()]
        
        folder_mappings[folder] = local_classes
        
        # Ajout des nouvelles classes √† la liste globale
        for c in local_classes:
            if c not in global_classes:
                global_classes.append(c)

    print(f"üìã Liste globale des classes ({len(global_classes)}) : {global_classes}")

    # 3. Collecter et Convertir les Labels
    all_pairs = []

    for folder in sub_datasets:
        img_dir = os.path.join(folder, 'images')
        lbl_dir = os.path.join(folder, 'labels')
        
        # Mapping local (index -> nom)
        local_classes = folder_mappings[folder]
        
        # Cr√©ation du mapping ID (index_local -> index_global)
        # Ex: si "Photo" est index 0 ici, mais index 5 au global, id_map[0] = 5
        id_map = {}
        for local_idx, name in enumerate(local_classes):
            global_idx = global_classes.index(name)
            id_map[local_idx] = global_idx
            
        # Parcourir les images de ce sous-dossier
        if os.path.exists(img_dir):
            images = glob.glob(os.path.join(img_dir, "*"))
            for img_path in images:
                if img_path.lower().endswith(('.jpg', '.jpeg', '.png')):
                    basename = os.path.basename(img_path)
                    txt_name = os.path.splitext(basename)[0] + ".txt"
                    lbl_path = os.path.join(lbl_dir, txt_name)
                    
                    if os.path.exists(lbl_path):
                        # On stocke le chemin image, le chemin label source, et le mapping √† appliquer
                        all_pairs.append({
                            'img': img_path,
                            'lbl': lbl_path,
                            'map': id_map
                        })

    print(f"üì¶ Total images trouv√©es : {len(all_pairs)}")
    if len(all_pairs) == 0: raise ValueError("Aucune image trouv√©e !")

    # 4. M√©langer et Splitter
    random.seed(42)
    random.shuffle(all_pairs)
    split_idx = int(len(all_pairs) * split_ratio)
    train_data = all_pairs[:split_idx]
    val_data = all_pairs[split_idx:]

    # Fonction pour copier et r√©√©crire les labels
    def process_files(data_list, img_dest_dir, lbl_dest_dir):
        for item in data_list:
            # Copie de l'image
            shutil.copy(item['img'], img_dest_dir)
            
            # Lecture, conversion et √©criture du label
            dest_lbl_path = os.path.join(lbl_dest_dir, os.path.basename(item['lbl']))
            
            new_lines = []
            with open(item['lbl'], 'r') as f_in:
                for line in f_in:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        old_cls_id = int(parts[0])
                        # Conversion de l'ID !
                        if old_cls_id in item['map']:
                            new_cls_id = item['map'][old_cls_id]
                            # On reconstruit la ligne avec le nouvel ID
                            new_line = f"{new_cls_id} " + " ".join(parts[1:])
                            new_lines.append(new_line)
            
            # Sauvegarde du nouveau label
            with open(dest_lbl_path, 'w') as f_out:
                f_out.write("\n".join(new_lines))

    print("‚è≥ R√©√©criture des labels et copie des fichiers...")
    process_files(train_data, dirs['train_img'], dirs['train_lbl'])
    process_files(val_data, dirs['val_img'], dirs['val_lbl'])

    # 5. Cr√©ation du YAML final
    yaml_content = {
        'path': dest_root,
        'train': 'images/train',
        'val': 'images/val',
        'names': {i: name for i, name in enumerate(global_classes)}
    }
    
    yaml_path = os.path.join(WORKING_DIR, 'data.yaml')
    with open(yaml_path, 'w') as f:
        yaml.dump(yaml_content, f)
        
    return yaml_path, global_classes

# Lancement
try:
    YAML_PATH, CLASS_NAMES = merge_and_remap_datasets(INPUT_DATASET_ROOT, TEMP_DATASET_DIR)
    print(f"‚úÖ Dataset fusionn√© pr√™t ! YAML : {YAML_PATH}")
except Exception as e:
    print(f"‚ùå Erreur critique : {e}")
    exit()



# ==============================================================================
# 3. FONCTIONS UTILITAIRES
# ==============================================================================
def evaluate_model(model_path, data_yaml, split='val'):
    print(f"üìä √âvaluation du mod√®le : {model_path} sur {split}...")
    try:
        model = YOLO(model_path)
        results = model.val(data=data_yaml, split=split, plots=False, verbose=False)
        metrics = {
            "mAP50": results.box.map50,
            "mAP50-95": results.box.map,
            "Precision": results.box.mp,
            "Recall": results.box.mr,
            "Fitness": results.fitness
        }
        return metrics
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible d'√©valuer : {e}")
        return {"mAP50": 0, "mAP50-95": 0, "Precision": 0, "Recall": 0}

def plot_comparison(before_metrics, after_metrics, save_dir):
    labels = list(before_metrics.keys())
    before_vals = list(before_metrics.values())
    after_vals = list(after_metrics.values())
    x = range(len(labels))
    width = 0.35
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar([i - width/2 for i in x], before_vals, width, label='Avant Fine-Tuning', color='gray')
    ax.bar([i + width/2 for i in x], after_vals, width, label='Apr√®s Fine-Tuning', color='green')
    ax.set_ylabel('Scores')
    ax.set_title('Comparaison des Performances')
    ax.set_xticks(x)
    ax.set_xticklabels(labels)
    ax.legend()
    plt.savefig(os.path.join(save_dir, "comparison_report.png"))
    plt.close()

# ==============================================================================
# 4. EVALUATION INITIALE
# ==============================================================================
print("\n--- 1. √âVALUATION PR√âALABLE ---")
pre_metrics = evaluate_model('yolov8n.pt', YAML_PATH, split='val')

# ==============================================================================
# 5. FINE-TUNING
# ==============================================================================
print("\n--- 2. LANCEMENT DE L'ENTRA√éNEMENT ---")

FORCE_RESTART = True 

last_checkpoint = os.path.join(MODEL_DIR, "weights", "last.pt")
resume_training = False
model_to_load = 'yolov8n.pt'

if FORCE_RESTART:
    print("üßπ Nettoyage de l'ancien dossier d'entra√Ænement pour recommencer √† z√©ro...")
    if os.path.exists(MODEL_DIR):
        shutil.rmtree(MODEL_DIR) # Supprime le dossier 'checkpoint_run'
    resume_training = False

elif os.path.exists(last_checkpoint):
    print(f"üîÑ Reprise de l'entra√Ænement depuis : {last_checkpoint}")
    resume_training = True
    model_to_load = last_checkpoint

# Chargement du mod√®le
model = YOLO(model_to_load)

train_args = {
    "data": YAML_PATH,
    "epochs": 100,
    "patience": 50,
    "batch": 16,
    "imgsz": 640,
    "project": PROJECT_NAME,
    "name": RUN_NAME,
    "exist_ok": True,
    "pretrained": True,
    "optimizer": 'auto',
    "verbose": True,
    "seed": 42,
    "freeze": 10,
    "resume": resume_training
}

results = model.train(**train_args)

# ==============================================================================
# 6. EVALUATION FINALE
# ==============================================================================
print("\n--- 3. √âVALUATION POST-ENTRA√éNEMENT ---")
post_metrics = evaluate_model(FINAL_MODEL_PATH, YAML_PATH, split='val')
plot_comparison(pre_metrics, post_metrics, WORKING_DIR)

results_csv = os.path.join(MODEL_DIR, "results.csv")
if os.path.exists(results_csv):
    df = pd.read_csv(results_csv)
    df.columns = [c.strip() for c in df.columns]
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(df['train/box_loss'], label='Train Box Loss')
    plt.plot(df['val/box_loss'], label='Val Box Loss')
    plt.title("Loss")
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(df['metrics/mAP50(B)'], label='mAP 50')
    plt.title("Pr√©cision (mAP)")
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(WORKING_DIR, "training_curves.png"))
    plt.close()

# ==============================================================================
# 7. LOGIQUE M√âTIER
# ==============================================================================
print("\n--- 4. TEST DE LOGIQUE M√âTIER ---")
def analyze_document(image_path, model_path):
    model = YOLO(model_path)
    img = cv2.imread(image_path)
    if img is None: return {"Erreur": "Image non trouv√©e"}
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    results = model(img_rgb)[0]
    doc_type = "Inconnu"
    dates_extracted = {}
    
    for box in results.boxes:
        cls_id = int(box.cls[0])
        # Protection si le mod√®le pr√©dit une classe hors liste
        if cls_id < len(model.names):
            label = model.names[cls_id]
        else:
            label = str(cls_id)
            
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        
        # Adaptez ces mots-cl√©s selon VOS classes r√©elles trouv√©es dans classes.txt
        if any(x in label.upper() for x in ["CNI", "BANCAIRE", "PASSEPORT", "PERMIS"]): 
            doc_type = label
        
        if "DATE" in label.upper():
            roi = img_rgb[y1:y2, x1:x2]
            gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)
            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
            text = pytesseract.image_to_string(thresh, config='--psm 6').strip()
            dates_extracted[label] = text

    status = "IND√âTERMIN√â"
    validity_msg = ""
    today = datetime.now()
    exp_date_obj = None
    
    for key, val in dates_extracted.items():
        if "EXP" in key.upper() or "VALID" in key.upper():
            try: exp_date_obj = parser.parse(val, dayfirst=True)
            except: pass
    
    if exp_date_obj:
        if exp_date_obj > today:
            status = "VALIDE"
            validity_msg = f"Valide jusqu'au {exp_date_obj.strftime('%d/%m/%Y')}"
        else:
            status = "EXPIR√â"
            validity_msg = f"Expir√© le {exp_date_obj.strftime('%d/%m/%Y')}"
    elif doc_type != "Inconnu":
        status = "INFO"
        validity_msg = "Date d'expiration non d√©tect√©e, validation impossible."
    
    return {"Type": doc_type, "Dates": dates_extracted, "Statut": status, "Msg": validity_msg}

# ==============================================================================
# 8. SAUVEGARDE FINALE
# ==============================================================================
print("\n--- 5. PR√âPARATION DU FICHIER √Ä T√âL√âCHARGER ---")
DOWNLOAD_FILENAME = "modele_final_complet.pt"
DESTINATION_PATH = os.path.join(WORKING_DIR, DOWNLOAD_FILENAME)

if os.path.exists(FINAL_MODEL_PATH):
    shutil.copy(FINAL_MODEL_PATH, DESTINATION_PATH)
    print(f"üéâ SUCCESS ! Le mod√®le a √©t√© copi√© √† la racine.")
    print(f"üëâ T√©l√©chargez '{DOWNLOAD_FILENAME}' depuis l'onglet Output.")
else:
    print(f"‚ùå Erreur : Le fichier {FINAL_MODEL_PATH} n'a pas √©t√© trouv√©.")





import os
from IPython.display import FileLink

# Compresse tout le dossier actuel (.) dans 'tout_mon_travail.zip' en excluant les zip existants
os.system("zip -r -q tout_mon_travail.zip . -x '*.zip'")

# Affiche le lien de t√©l√©chargement
FileLink(r'tout_mon_travail.zip')
